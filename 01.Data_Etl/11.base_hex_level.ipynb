{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas  as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import h3 as h3\n",
    "\n",
    "import re\n",
    "\n",
    "import os\n",
    "from os.path import isfile, join\n",
    "from pathlib import Path\n",
    "from os import listdir\n",
    "import os\n",
    "os.getcwd()\n",
    "\n",
    "path =  Path(os.getcwd())\n",
    "root = path.parent.absolute()\n",
    "\n",
    "root"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Import Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1 Base Table\n",
    "##### LA County shape file transposed to Uber Hexegons at level 8. ~.75 square km\n",
    "##### This process takes a shape file and maps it to hex files for a given level. The output of the mapping is the a unique hex_id for the hexegon and the shape geometry\n",
    "##### https://h3geo.org/docs/core-library/restable/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_all = gpd.read_file(root / 'X.data' / 'h3_processed_data' / 'base_map_hex_all' /'base_map_hex_all.shp')\n",
    "print(gdf_all.shape)\n",
    "gdf_all.sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_all = gdf_all[~(gdf_all.hex_id == '0')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 City and District shape files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "city_label = pd.read_csv(root / 'X.data' / 'h3_processed_data'/ 'city_labels_hex.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "district_labels = pd.read_csv(root / 'X.data' / 'h3_processed_data'/ 'district_labels_hex.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3 Nodes\n",
    "##### LA County nodes - pulled from Ptyhon OSMNX. All street intersections\n",
    "#####   The lat and lon for each node was mapped hex id for joining onto the the county hex file\n",
    "##### https://github.com/gboeing/osmnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "highway_cnts = pd.read_csv(root / 'X.data' /  'nodes_and_edges' / 'nodes_highway_cnts.csv' )\n",
    "display(highway_cnts.sample())\n",
    "highway_cnts.highway.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "street_cnts = pd.read_csv(root / 'X.data' / 'nodes_and_edges' / 'nodes_street_count_cnts.csv' )\n",
    "#display(street_cnts.sample())\n",
    "street_cnts_grps = street_cnts.groupby('hex_id').street_count.agg('max')\n",
    "street_cnts_grps = street_cnts_grps.reset_index()\n",
    "street_cnts_grps = street_cnts_grps[~(street_cnts_grps.hex_id == '0')]\n",
    "street_cnts_grps.columns = ['hex_id', 'node_street_count']\n",
    "street_cnts_grps.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_all = gdf_all.merge(street_cnts_grps, on = 'hex_id', how = 'left')\n",
    "gdf_all.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4 Edges\n",
    "#### LA County edges (streets) - pulled from Ptyhon OSMNX.\n",
    "##### These are the line geometry shape files. The will be joined using geo panda sjoin to the shape file for the hex\n",
    "##### https://github.com/gboeing/osmnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = gpd.read_file(root / 'X.data' / 'nodes_and_edges' / 'la_county_edges' / 'la_county_edges.shp')\n",
    "print(edges.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.5 Collision data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collision_hex = pd.read_csv(root / 'X.data' / 'h3_processed_data' / 'collisions_hex.csv')\n",
    "collision_hex.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Nodes (intersections) \n",
    "\n",
    "### 2.1 Prep node files by making a wide table.  One unique row per hex id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "highway_pivot = highway_cnts.pivot(index=\"hex_id\", columns=\"highway\", values=\"count\").fillna(0)\n",
    "highway_pivot.columns = 'node_'+highway_pivot.columns\n",
    "highway_pivot.reset_index(inplace = True)\n",
    "highway_pivot.sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orign_row_count = gdf_all.shape[0]\n",
    "gdf_all = gdf_all.merge(highway_pivot, on = 'hex_id', how = 'left')\n",
    "updated_row_count = gdf_all.shape[0]\n",
    "orign_row_count = updated_row_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_all.shape\n",
    "gdf_all.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#improvment could be to create this list dynamically\n",
    "counts_col_list = ['node_street_count','node_crossing', 'node_give_way',\n",
    "       'node_milestone', 'node_mini_roundabout', 'node_motorway_junction',\n",
    "       'node_stop', 'node_traffic_signals', 'node_trailhead',\n",
    "       'node_turning_circle', 'node_turning_loop']\n",
    "\n",
    "gdf_all.update(gdf_all[counts_col_list].fillna(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_all.sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Attach the neighboring nodes hex ids to the general table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# h3 k_ring returns the ring of hexegons touching a given h3.  \n",
    "# Set level \n",
    "# skin = 1 is first ring plus the hex itself.  \n",
    "# skin = 2 is second ring out plus ring 1 plus the hex itself, ect...\n",
    "def rking_neighbors(row, skins):\n",
    "    neighbors = h3.k_ring(row.hex_id, skins)\n",
    "    neighbors_list = list(neighbors)\n",
    "    return(neighbors_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_all['hex_neighbors_0_ids'] = gdf_all.apply(lambda x: rking_neighbors(x, skins = 0), axis=1)\n",
    "gdf_all['hex_neighbors_1_ids'] = gdf_all.apply(lambda x: rking_neighbors(x, skins = 1), axis=1)\n",
    "gdf_all['hex_neighbors_2_ids'] = gdf_all.apply(lambda x: rking_neighbors(x, skins = 2), axis=1)\n",
    "gdf_all.sample(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Neighboring Hex Counts\n",
    "#### For all the nodes columns, attach the count for the hex and it ring 1 and 2. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gd_all_1_tall = gdf_all[['hex_id', 'hex_neighbors_1_ids']].explode('hex_neighbors_1_ids')\n",
    "gd_all_1_tall = gd_all_1_tall.merge(gdf_all[counts_col_list + ['hex_id']], \n",
    "                                    left_on = 'hex_neighbors_1_ids', \n",
    "                                    right_on = 'hex_id',\n",
    "                                    how = 'inner')\n",
    "#print(gd_all_1_tall.columns)\n",
    "gd_all_1_tall = gd_all_1_tall[['hex_id_x'] + counts_col_list]\n",
    "gd_all_1_grp_sum = gd_all_1_tall.groupby('hex_id_x')[counts_col_list].agg('sum')\n",
    "gd_all_1_grp_cnt = gd_all_1_tall.groupby('hex_id_x')[counts_col_list[0]].agg('count')\n",
    "#gd_all_1_grp.columns = ['hex_id', 'neighbor_1_collision_count']\n",
    "gd_all_1_grp_sum.columns = 'neighbor_1_' + gd_all_1_grp_sum.columns\n",
    "\n",
    "gd_all_1_grp_sum.index.names = ['hex_id']\n",
    "gd_all_1_grp_sum.reset_index(inplace = True)\n",
    "gd_all_1_grp_cnt = gd_all_1_grp_cnt.reset_index()\n",
    "gd_all_1_grp_cnt.columns = ['hex_id', 'neighbor_1_count']\n",
    "\n",
    "gdf_all = gdf_all.merge(gd_all_1_grp_sum, on = 'hex_id', how = 'left')\n",
    "gdf_all = gdf_all.merge(gd_all_1_grp_cnt, on = 'hex_id', how = 'left')\n",
    "gdf_all.sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gd_all_2_tall = gdf_all[['hex_id', 'hex_neighbors_2_ids']].explode('hex_neighbors_2_ids')\n",
    "gd_all_2_tall = gd_all_2_tall.merge(gdf_all[counts_col_list + ['hex_id']], \n",
    "                                    left_on = 'hex_neighbors_2_ids', \n",
    "                                    right_on = 'hex_id',\n",
    "                                    how = 'inner')\n",
    "#print(gd_all_1_tall.columns)\n",
    "gd_all_2_tall = gd_all_2_tall[['hex_id_x'] + counts_col_list]\n",
    "gd_all_2_grp_sum = gd_all_2_tall.groupby('hex_id_x')[counts_col_list].agg('sum')\n",
    "gd_all_2_grp_cnt = gd_all_2_tall.groupby('hex_id_x')[counts_col_list[0]].agg('count')\n",
    "#gd_all_1_grp.columns = ['hex_id', 'neighbor_1_collision_count']\n",
    "gd_all_2_grp_sum.columns = 'neighbor_2_' + gd_all_2_grp_sum.columns\n",
    "\n",
    "gd_all_2_grp_sum.index.names = ['hex_id']\n",
    "gd_all_2_grp_sum.reset_index(inplace = True)\n",
    "gd_all_2_grp_cnt = gd_all_2_grp_cnt.reset_index()\n",
    "gd_all_2_grp_cnt.columns = ['hex_id', 'neighbor_2_count']\n",
    "\n",
    "gdf_all = gdf_all.merge(gd_all_2_grp_sum, on = 'hex_id', how = 'left')\n",
    "gdf_all = gdf_all.merge(gd_all_2_grp_cnt, on = 'hex_id', how = 'left')\n",
    "gdf_all.sample(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5 Nearest Hex Neighbor Average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = re.compile(\"neighbor_1_*\")\n",
    "neighbor_col_list = list(filter(r.match, gdf_all.columns))\n",
    "neighbor_col_list.remove('neighbor_1_count')\n",
    "neighbor_col_list\n",
    "\n",
    "for nc in neighbor_col_list:\n",
    "    gdf_all[nc + '_ave'] = gdf_all[nc] / gdf_all.neighbor_1_count\n",
    "\n",
    "r = re.compile(\"neighbor_2_*\")\n",
    "neighbor_col_list = list(filter(r.match, gdf_all.columns)) \n",
    "neighbor_col_list.remove('neighbor_2_count')\n",
    "neighbor_col_list\n",
    "\n",
    "for nc in neighbor_col_list:\n",
    "    gdf_all[nc + '_ave'] = gdf_all[nc] / gdf_all.neighbor_2_count\n",
    "\n",
    "gdf_all.sample(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 City and Distric Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_all = gdf_all.merge(city_label, on = 'hex_id', how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "city_label.sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_all = gdf_all.merge(district_labels, on = 'hex_id', how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_all.sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_all.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 Edges (streets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_all = gpd.sjoin(gdf_all, edges[['geometry', 'highway']].to_crs(epsg=3857), how='left', predicate='intersects')\n",
    "gdf_all.sample(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorter = ['motorway_link'\n",
    "                      ,'motorway'\n",
    "                      ,'primary'\n",
    "                      ,'secondary'\n",
    "                      ,'residential'\n",
    "                      ,'primary_link'\n",
    "                      ,'secondary_link'\n",
    "                      ,'tertiary'\n",
    "                      ,'trunk'\n",
    "                      ,'unclassified'\n",
    "                      ,'other']\n",
    "\n",
    "gdf_all['highway_updated'] = 'other'\n",
    "gdf_all['highway_updated'][gdf_all['highway'].isin(sorter)] = gdf_all['highway']\n",
    "gdf_all.highway_updated.value_counts()\n",
    "sorterIndex = dict(zip(sorter, range(len(sorter))))\n",
    "\n",
    "gdf_all['highway_rank'] = gdf_all.highway_updated.map(sorterIndex)\n",
    "#gdf_hex_hwy.sort_values(by=['hex_id', 'highway_rank']).head()\n",
    "gdf_all = gdf_all.groupby('hex_id').first()\n",
    "gdf_all.reset_index(inplace = True)\n",
    "gdf_all.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_all['highway'] = gdf_all['highway_updated']\n",
    "gdf_all = gdf_all.drop(columns = ['highway_updated','highway_rank', 'index_right'])\n",
    "gdf_all.sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gdf_all.shape)\n",
    "edges[['geometry', 'oneway']].oneway.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_all = gpd.sjoin(gdf_all, edges[['geometry', 'oneway']].to_crs(epsg=3857), how='left', predicate='intersects')\n",
    "gdf_all.sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorter = [1,0]\n",
    "gdf_all['oneway_updated'] = 'other'\n",
    "gdf_all['oneway_updated'][gdf_all['oneway'].isin(sorter)] = gdf_all['oneway']\n",
    "gdf_all.oneway_updated.value_counts()\n",
    "sorterIndex = dict(zip(sorter, range(len(sorter))))\n",
    "\n",
    "gdf_all['oneway_rank'] = gdf_all.oneway_updated.map(sorterIndex)\n",
    "#gdf_hex_hwy.sort_values(by=['hex_id', 'highway_rank']).head()\n",
    "gdf_all = gdf_all.groupby('hex_id').first()\n",
    "gdf_all.reset_index(inplace = True)\n",
    "gdf_all.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_all['oneway'] = gdf_all['oneway_updated']\n",
    "gdf_all = gdf_all.drop(columns = ['oneway_updated','oneway_rank', 'index_right'])\n",
    "gdf_all.sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_all = gpd.sjoin(gdf_all, edges[['geometry', 'lanes']].to_crs(epsg=3857), how='left', predicate='intersects')\n",
    "gdf_all.sample(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_all = gdf_all.sort_values('lanes', ascending = False)\n",
    "gdf_all = gdf_all.groupby('hex_id').first()\n",
    "gdf_all.reset_index(inplace = True)\n",
    "gdf_all = gdf_all.drop(columns = ['index_right'])\n",
    "gdf_all.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_all = gpd.sjoin(gdf_all, edges[['geometry', 'maxspeed']].to_crs(epsg=3857), how='left', predicate='intersects')\n",
    "gdf_all = gdf_all.sort_values('maxspeed', ascending = False)\n",
    "gdf_all = gdf_all.groupby('hex_id').first()\n",
    "gdf_all.reset_index(inplace = True)\n",
    "gdf_all = gdf_all.drop(columns = ['index_right'])\n",
    "gdf_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_all = gpd.sjoin(gdf_all, edges[['geometry', 'width']].to_crs(epsg=3857), how='left', predicate='intersects')\n",
    "gdf_all = gdf_all.sort_values('width', ascending = False)\n",
    "gdf_all = gdf_all.groupby('hex_id').first()\n",
    "gdf_all.reset_index(inplace = True)\n",
    "gdf_all = gdf_all.drop(columns = ['index_right'])\n",
    "gdf_all.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges.loc[edges.bridge != 'yes', 'bridge'] = 'no'\n",
    "gdf_all = gpd.sjoin(gdf_all, edges[['geometry', 'bridge']].to_crs(epsg=3857), how='left', predicate='intersects')\n",
    "gdf_all = gdf_all.sort_values('bridge', ascending = False)\n",
    "gdf_all = gdf_all.groupby('hex_id').first()\n",
    "gdf_all.reset_index(inplace = True)\n",
    "gdf_all = gdf_all.drop(columns = ['index_right'])\n",
    "gdf_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_all.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_edge_filter = gpd.sjoin(gdf_all, edges.to_crs(epsg=3857), how = 'inner')\n",
    "gdf_edge_filter.reset_index(inplace = True)\n",
    "\n",
    "gdf_edge_filter = gdf_edge_filter[['hex_id']].drop_duplicates()\n",
    "gdf_node_filter = highway_cnts[['hex_id']].drop_duplicates()\n",
    "\n",
    "gdf_filtered = pd.concat([gdf_edge_filter, gdf_node_filter], axis = 0)\n",
    "valid_array = gdf_filtered['hex_id'].values\n",
    "print(valid_array)\n",
    "\n",
    "mask = gdf_all['hex_id'].isin(valid_array)\n",
    "\n",
    "gdf_all['valid_accident_location_filter'] = mask\n",
    "\n",
    "print(sum(mask))\n",
    "\n",
    "gdf_all.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Collisions by Year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Neighbor collisions count.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collision_hex_grp = collision_hex.groupby(['hex_id', 'collision_year']).accident_count.agg('sum').to_frame('collisions').reset_index()\n",
    "collision_hex_grp['collision_year'] = collision_hex_grp['collision_year']\n",
    "collision_hex_grp.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gd_all_0_tall = gdf_all[['hex_id', 'hex_neighbors_0_ids']].explode('hex_neighbors_0_ids')\n",
    "gd_all_0_tall = gd_all_0_tall.merge(collision_hex_grp, \n",
    "                                    left_on = 'hex_neighbors_0_ids', \n",
    "                                    right_on = 'hex_id',\n",
    "                                    how = 'inner')\n",
    "\n",
    "gd_all_0_tall = gd_all_0_tall[['hex_id_x', 'collision_year', 'collisions']]\n",
    "\n",
    "gd_all_0_tall = gd_all_0_tall.groupby(['hex_id_x', 'collision_year']).collisions.agg('sum').to_frame('neighbor0_collision').reset_index()\n",
    "#display(gd_all_1_tall.head(1))\n",
    "\n",
    "pivot_neighbor_0 = gd_all_0_tall.pivot_table(index = 'hex_id_x', columns = 'collision_year', values = 'neighbor0_collision')\n",
    "#display(pivot_neighbor_1.head(1))\n",
    "#print(pivot_neighbor_1.columns)\n",
    "pivot_neighbor_0.columns = [\"_\".join(('collisions_neighbor0',str(j))) for j in pivot_neighbor_0.columns]\n",
    "pivot_neighbor_0.index.names = ['hex_id']\n",
    "pivot_neighbor_0 = pivot_neighbor_0.reset_index()\n",
    "pivot_neighbor_0 = pivot_neighbor_0.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gd_all_1_tall = gdf_all[['hex_id', 'hex_neighbors_1_ids']].explode('hex_neighbors_1_ids')\n",
    "gd_all_1_tall = gd_all_1_tall.merge(collision_hex_grp, \n",
    "                                    left_on = 'hex_neighbors_1_ids', \n",
    "                                    right_on = 'hex_id',\n",
    "                                    how = 'inner')\n",
    "\n",
    "gd_all_1_tall = gd_all_1_tall[['hex_id_x', 'collision_year', 'collisions']]\n",
    "\n",
    "gd_all_1_tall = gd_all_1_tall.groupby(['hex_id_x', 'collision_year']).collisions.agg('sum').to_frame('neighbor1_collision').reset_index()\n",
    "#display(gd_all_1_tall.head(1))\n",
    "\n",
    "pivot_neighbor_1 = gd_all_1_tall.pivot_table(index = 'hex_id_x', columns = 'collision_year', values = 'neighbor1_collision')\n",
    "#display(pivot_neighbor_1.head(1))\n",
    "#print(pivot_neighbor_1.columns)\n",
    "pivot_neighbor_1.columns = [\"_\".join(('collisions_neighbor1',str(j))) for j in pivot_neighbor_1.columns]\n",
    "pivot_neighbor_1.index.names = ['hex_id']\n",
    "pivot_neighbor_1 = pivot_neighbor_1.reset_index()\n",
    "pivot_neighbor_1 = pivot_neighbor_1.fillna(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gd_all_2_tall = gdf_all[['hex_id', 'hex_neighbors_2_ids']].explode('hex_neighbors_2_ids')\n",
    "gd_all_2_tall = gd_all_2_tall.merge(collision_hex_grp, \n",
    "                                    left_on = 'hex_neighbors_2_ids', \n",
    "                                    right_on = 'hex_id',\n",
    "                                    how = 'inner')\n",
    "\n",
    "gd_all_2_tall = gd_all_2_tall[['hex_id_x', 'collision_year', 'collisions']]\n",
    "\n",
    "gd_all_2_tall = gd_all_2_tall.groupby(['hex_id_x', 'collision_year']).collisions.agg('sum').to_frame('neighbor1_collision').reset_index()\n",
    "#display(gd_all_1_tall.head(1))\n",
    "\n",
    "pivot_neighbor_2 = gd_all_2_tall.pivot_table(index = 'hex_id_x', columns = 'collision_year', values = 'neighbor1_collision')\n",
    "#display(pivot_neighbor_1.head(1))\n",
    "#print(pivot_neighbor_1.columns)\n",
    "pivot_neighbor_2.columns = [\"_\".join(('collisions_neighbor2',str(j))) for j in pivot_neighbor_2.columns]\n",
    "pivot_neighbor_2.index.names = ['hex_id']\n",
    "pivot_neighbor_2 = pivot_neighbor_2.reset_index()\n",
    "pivot_neighbor_2 = pivot_neighbor_2.fillna(0)\n",
    "pivot_neighbor_2.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(pivot_neighbor_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_all.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_all = gdf_all.merge(pivot_neighbor_0, on = 'hex_id', how = 'left')\n",
    "gdf_all = gdf_all.merge(pivot_neighbor_1, on = 'hex_id', how = 'left')\n",
    "gdf_all = gdf_all.merge(pivot_neighbor_2, on = 'hex_id', how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_all.sample(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_all.to_csv(root / 'X.data' / 'joined_data' / 'base_location_data.csv', index = False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
