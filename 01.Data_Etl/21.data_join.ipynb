{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1dbb9954-b5d1-47ae-98bc-5bdb5c900258",
   "metadata": {},
   "source": [
    "### Model Data Initial Join\n",
    "* Base hex data with node and edge characteristics and target variable (hex_id, collision year/month/day of week/hour).\n",
    "* Join prior year accident data information (hex_id and year)\n",
    "* Join TTV split column (hex_id, collision year/month/day of week/hour, accident id, ttv_split)\n",
    "* Join weather data - needs to be created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb85195-6cc8-460f-8ad7-fea601042f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import datetime\n",
    "from datetime import datetime\n",
    "\n",
    "import boto3\n",
    "import awswrangler\n",
    "\n",
    "import re\n",
    "\n",
    "import os\n",
    "from os.path import isfile, join\n",
    "from pathlib import Path\n",
    "from os import listdir\n",
    "import os\n",
    "os.getcwd()\n",
    "\n",
    "#from commons import download_data, find_vcs_root\n",
    "\n",
    "path =  Path(os.getcwd())\n",
    "root = path.parent.absolute()\n",
    "\n",
    "root\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2020c6da-397f-464c-ba23-36986d07869a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from aws_secrets import aws_access_key_id, aws_secret_access_key, aws_session_token\n",
    "\n",
    "my_session = boto3.Session(\n",
    "    aws_access_key_id=aws_access_key_id,\n",
    "    aws_secret_access_key=aws_secret_access_key,\n",
    "    aws_session_token = aws_session_token\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4bcc48e-344b-4499-96b5-2adc95475822",
   "metadata": {},
   "source": [
    "### 1. Import Base data\n",
    "This includes most of the base data for modeling\n",
    "* Node and edge information (intersections and streets.\n",
    "* Includes the accident data as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89839c02-21ca-41d1-9671-1fbd72fd5532",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_s3_bucket = 'traffic-data-bucket'\n",
    "raw_path_dir = 'joined_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf1813a2-223d-41ee-baa8-e9630ccacf29",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_df = awswrangler.s3.read_csv(path = 's3://traffic-data-bucket/joined_data/base_location_data.csv',\n",
    "                       boto3_session=my_session, use_threads=True\n",
    "                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "843edebf-1d9e-4159-aa16-f71b6ba49be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0601d8c2-056a-49e3-b2f6-91cab7f510e1",
   "metadata": {},
   "source": [
    "### 2. Prior Years Accident Information\n",
    "Various stats regarding collision history for the hexegon and its neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0029eb13-18e9-4fa8-9266-23cfb775e4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_s3_bucket = 'traffic-data-bucket'\n",
    "raw_path_dir = 'joined_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "140d4313-ecfd-4eab-8cf3-4725d33a1e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "prior_collision_hist_dict = {}\n",
    "coll_year_dict = [2014, 2015, 2016, 2017, 2018, 2019, 2020]\n",
    "\n",
    "for key in coll_year_dict:\n",
    "    print(key)\n",
    "    #base_dict[key] = pd.read_csv(root / 'X.data' / 'joined_data' / ('base_location_' + str(key) + '_collision_data.csv'))\n",
    "    \n",
    "    raw_path = f\"s3://{raw_s3_bucket}/{raw_path_dir}/{'base_location_' + str(key) + '_collision_data.csv'}\"\n",
    "    prior_collision_hist_dict[key] = awswrangler.s3.read_csv(path = raw_path, boto3_session=my_session, use_threads=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b48136-f012-4e27-a3e5-cdf9fff723db",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in coll_year_dict:\n",
    "    temp_df = prior_collision_hist_dict[key]\n",
    "    temp_df['collision_year'] = key\n",
    "    prior_collision_hist_dict[key] = temp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "640a1345-c611-4227-b934-bc569934a9ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#stack the dictionary of pd frames\n",
    "prior_collision_hist_df = pd.concat(prior_collision_hist_dict.values(), ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c9f3f7-2932-4834-a189-276489a338e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "prior_collision_hist_df.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b9e5751-7f76-4403-8096-24123f04ab66",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 3. Import Train-Test-Validation split data\n",
    "This includes all collision date and time\n",
    "* accident_count = 1 is a positive sample\n",
    "* accident_count = 0 is a negative sample\n",
    "* ttv_split values are Train, Test, Validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c120e6fd-5a01-4414-9151-0c3433cb5e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TTV_df = pd.read_csv(root / 'X.data' / 'TTV_splits' / 'TTV_data.csv')\n",
    "ttv_df = awswrangler.s3.read_csv(path = 's3://traffic-data-bucket/TTV_splits/TTV_data.csv', boto3_session=my_session, use_threads=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54307065-13d8-47a2-803a-7477d05c5e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "ttv_df.sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d656cc08-ca24-4dfd-b256-cae8fc812b4f",
   "metadata": {},
   "source": [
    "### 4. Import weather\n",
    "Weather data for LA county."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b192cb13-4b67-4894-91fd-10a34301c022",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "weather_df = awswrangler.s3.read_csv(path = 's3://traffic-data-bucket/weather/LA_weather_data_updated.csv', boto3_session=my_session, use_threads=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39567e03-32be-48a5-affa-f9103a8519a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df.sample(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "803e65f6-28c8-47c3-b2a9-eda3d039244f",
   "metadata": {},
   "source": [
    "### 4. Amenities\n",
    "Open Streets information for counts\n",
    "* Restaurants, bars, colleges and schools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "236ba9f6-0445-4861-8f38-5d159c66d7eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ammenities_df = awswrangler.s3.read_csv(path = 's3://traffic-data-bucket/nodes_and_edges/la_county_amenities/la_county_ammenities.csv', boto3_session=my_session, use_threads=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a7b5721-0909-4f2d-b1e8-32d1df5bdcf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ammenities_df.sample(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e656dbd-4db0-4958-8c42-8c894d83784e",
   "metadata": {},
   "source": [
    "### 5. Join Data\n",
    "* train-test-validate (TTV) split had hex id and date/hour \n",
    "* base data - join on hex id\n",
    "* collision history - join on hex id, collision year\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5719021f-edc6-48e9-9619-a7ca8e6f1202",
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_df1 = ttv_df[['hex_id','collision_date', 'collision_year','collision_month',\n",
    "                     'collision_dayofweek','collision_hour',\n",
    "                     'accident_count','ttv_split']].merge(base_df, on = 'hex_id', how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac9e2938-a841-4e12-bce6-6f84978473e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#should have the same number of rows\n",
    "ttv_df.shape[0] == joined_df1.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa8a76d-e291-4fb7-baec-59e8db6f5070",
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_df2 = joined_df1.merge(prior_collision_hist_df, on = ['hex_id', 'collision_year'], how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63199a3b-ea82-4203-b489-e1983a5285ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#should have the same number of rows\n",
    "joined_df2.shape[0] == joined_df1.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be3e09bd-63f9-4800-99ec-af3ab3a5d185",
   "metadata": {},
   "outputs": [],
   "source": [
    "#make sure they are the same format\n",
    "joined_df2['collision_date'] = pd.to_datetime(joined_df2['collision_date']).dt.date\n",
    "weather_df['date'] = pd.to_datetime(weather_df['date']).dt.date \n",
    "joined_df3 = joined_df2.merge(weather_df, left_on = ['collision_date'], right_on = ['date'], how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cace494-1b84-4515-abd1-b427fcc6af3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#should have the same number of rows\n",
    "joined_df2.shape[0] == joined_df3.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a418d42-57e8-4bfa-92ba-6b6040ee8035",
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_df4 = joined_df3.merge(ammenities_df, on = ['hex_id'], how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a29dc764-d23a-41ee-b1da-7203885bcd75",
   "metadata": {},
   "outputs": [],
   "source": [
    "#should have the same number of rows\n",
    "joined_df4.shape[0] == joined_df3.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284a3b6d-4a47-4acc-88db-6b7fb9a6564e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# joined_df4.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e46607d6-0d2d-4f16-9176-4460cfe52f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_df4.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa1ae4bb-50b3-477c-aeab-a150dfa7a223",
   "metadata": {},
   "source": [
    "## 6. Save to parquet and upload to S3 bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d555ee-f552-41a5-8f49-6ad0dd42e38f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# upload to root of S3 Bucket\n",
    "# awswrangler.s3.to_csv(df=joined_df4, path = 's3://traffic-data-bucket/model_data/model_data_pre_transformation.csv', index=False,\n",
    "#                        boto3_session=my_session, use_threads=True\n",
    "#                        )\n",
    "\n",
    "awswrangler.s3.to_parquet(df=joined_df4, path = 's3://traffic-data-bucket/model_data/model_data_pre_transformation.parquet', index=False,\n",
    "                       boto3_session=my_session, use_threads=True\n",
    "                       )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f69d664-6615-417c-8568-fa01e5e3d682",
   "metadata": {},
   "source": [
    "### Create a local copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa610d4b-d97c-421d-8849-20d16a7d127e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a local copy\n",
    "# joined_df4.to_csv(root / 'X.data' / 'model_data_pre_transformation.csv', index = False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e83cc59-af90-4d4c-8e55-4d8ec7c0efce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:capstone]",
   "language": "python",
   "name": "conda-env-capstone-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
