{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a9d59001",
   "metadata": {},
   "source": [
    "# Prepare Transportation Injury Mapping System (TIMS) Data\n",
    "In this notebook we download the collision data for Los Angeles County which has data for years 2014 to 2020."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "12ddda41",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from h3 import h3\n",
    "import os\n",
    "from os.path import isfile, join\n",
    "from pathlib import Path\n",
    "from os import listdir\n",
    "\n",
    "import boto3\n",
    "import awswrangler\n",
    "# set name of S3 bucket\n",
    "s3_bucket = 'traffic-data-bucket'\n",
    "\n",
    "path =  Path(os.getcwd())\n",
    "root = path.parent.absolute()\n",
    "\n",
    "import warnings\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "\n",
    "h3_level = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e60250cb-f08f-4573-84f0-3ad4fa87c7cb",
   "metadata": {},
   "source": [
    "## 1. Connect to AWS Services"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8bb9d007-f70c-4cbb-9734-5eb95ba5dffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from aws_secrets import aws_access_key_id, aws_secret_access_key, aws_session_token\n",
    "\n",
    "my_session = boto3.Session(\n",
    "    aws_access_key_id=aws_access_key_id,\n",
    "    aws_secret_access_key=aws_secret_access_key,\n",
    "    aws_session_token = aws_session_token\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30f73171",
   "metadata": {},
   "source": [
    "## 2. Download collision data from S3 bucket using AWS Wrangler\n",
    "AWS Wrangler is used to read all files in the S3 Bucket with a .csv suffix into a single Pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b21ae205",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_path_dir = 'TIMS_raw_crashes/'\n",
    "\n",
    "# path of S3 bucket where collision data is stored\n",
    "raw_path = f\"s3://{s3_bucket}/{raw_path_dir}\"\n",
    "\n",
    "# read data from S3 bucket\n",
    "collision_df = awswrangler.s3.read_csv(path=raw_path, path_suffix=['.csv'], dataset=True,\n",
    "                                 boto3_session=my_session, use_threads=True, low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "59d73fe9-9c60-4ea5-9de2-fc0a8a719d0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(404681, 80)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collision_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "741737c8-ea04-42c4-94a8-8b061b71b016",
   "metadata": {},
   "outputs": [],
   "source": [
    "collision_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ff0ed65-b8ce-4963-99d9-b8e7f9102625",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 3. Clean and create time features\n",
    "The dataset contains some invalid times which will be dropped and from the `collission_date` variable we will extract the year, month, day, day of the week, and day of the year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c8527b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0:0>4 is a left padding of a string so if the string length is less than 4, add front ‘0’, e.g., 23 would become ‘0023’ \n",
    "collision_df['COLLISION_TIME']=collision_df['COLLISION_TIME'].apply(lambda x: '{0:0>4}'.format(x))\n",
    "\n",
    "# create a mask to remove records with invalid times\n",
    "# there are several rows that have '2500' entered as their collision time\n",
    "mask = collision_df['COLLISION_TIME']=='2500'\n",
    "\n",
    "# apply mask to capture records with valid times\n",
    "valid_time = collision_df[~mask]\n",
    "\n",
    "# create a dataframe of records with nonvalid times\n",
    "nonvalid_time = collision_df[mask]\n",
    "nonvalid_time['COLLISION_HOUR'] = 'none'\n",
    "# print number of records to drop\n",
    "print(nonvalid_time.shape)\n",
    "\n",
    "valid_time = valid_time.assign(COLLISION_HOUR=pd.to_datetime(valid_time.COLLISION_TIME, format='%H%M').dt.hour)\n",
    "valid_time = valid_time.assign(COLLISION_DATE=pd.to_datetime(valid_time.COLLISION_DATE, format='%Y-%m-%d'))\n",
    "\n",
    "# create date features\n",
    "valid_time['COLLISION_YEAR'] = valid_time.COLLISION_DATE.dt.year\n",
    "valid_time['COLLISION_MONTH'] = valid_time.COLLISION_DATE.dt.month\n",
    "valid_time['COLLISION_DAY'] = valid_time.COLLISION_DATE.dt.day\n",
    "valid_time['COLLISION_DAYOFWEEK'] = valid_time.COLLISION_DATE.dt.dayofweek\n",
    "valid_time['COLLISION_DAYOFYEAR'] = valid_time.COLLISION_DATE.dt.dayofyear\n",
    "\n",
    "valid_time.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d307496-946d-4682-a10b-5ac7ab1aa05d",
   "metadata": {},
   "source": [
    "Next, lowercase each column name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c0872ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_time.columns = [each_string.lower() for each_string in valid_time.columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc3e8e3c-5df5-4b15-980f-d92153345edf",
   "metadata": {},
   "source": [
    "## 4. Create and attach hexagons using H3 library\n",
    "`h3_level` refers to the size of each hexagon.  A higher value represents a larger hexagon which covers a larger area and smaller values represent smaller hexagons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f5739f0-32c4-4822-a572-40d18461983d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('H3 Level:', h3_level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83054369",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a function to convert latitude and longitude values to hexagons\n",
    "def lat_lng_to_h3(row):\n",
    "    return h3.geo_to_h3(row.point_y, row.point_x, h3_level)\n",
    "\n",
    "pd_dict = {}\n",
    "\n",
    "valid_time['hex_id'] = valid_time.apply(lat_lng_to_h3, axis=1)\n",
    "print(valid_time.shape)\n",
    "valid_time = valid_time.groupby(['hex_id', 'collision_year', 'collision_dayofyear', 'collision_month', 'collision_dayofweek', 'collision_hour']).first()\n",
    "valid_time.reset_index(inplace = True)\n",
    "\n",
    "valid_time_select = valid_time[['hex_id', 'collision_year', 'collision_dayofyear', 'collision_month', 'collision_dayofweek', 'collision_hour']]\n",
    "valid_time_select['accident_count'] = 1\n",
    "print(valid_time_select.shape)\n",
    "#valid_time_cnt.sample(3)\n",
    "#valid_time_cnt.columns = ['h3_'+str(level), 'collision_count_h3_'+str(level)]\n",
    "#pd_dict[key_val] = valid_time_cnt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e0e9717-1943-4244-9732-726e3ffdbb4f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 5. Upload processed data to S3 Bucket\n",
    "Convert the processed data to CSV and upload to the S3 bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18183084-2c19-4be2-a38e-c4ccc40a3dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# upload to a new folder in the bucket called h3_processed_data\n",
    "awswrangler.s3.to_csv(df=valid_time_select, path = f's3://{s3_bucket}/h3_processed_data/collisions_hex.csv', index=False,\n",
    "                       boto3_session=my_session, use_threads=True\n",
    "                       )\n",
    "# upload to root of S3 Bucket\n",
    "awswrangler.s3.to_csv(df=valid_time_select, path = f's3://{s3_bucket}/all_collisions_points.csv', index=False,\n",
    "                       boto3_session=my_session, use_threads=True\n",
    "                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9af5410-8b0d-4beb-903a-bbca438964e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:capstone]",
   "language": "python",
   "name": "conda-env-capstone-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
