{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import datetime\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "import re\n",
    "\n",
    "import os\n",
    "from os.path import isfile, join\n",
    "from pathlib import Path\n",
    "from os import listdir\n",
    "import os\n",
    "os.getcwd()\n",
    "\n",
    "#from commons import download_data, find_vcs_root\n",
    "\n",
    "path =  Path(os.getcwd())\n",
    "root = path.parent.absolute()\n",
    "\n",
    "root"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Import Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1 Base Table\n",
    "##### LA County shape file transposed to Uber Hexegons at level 8. ~.75 square km\n",
    "##### Import all hex and make a list of over day, hour and year and attach a random number for \n",
    "##### https://h3geo.org/docs/core-library/restable/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_df = pd.read_csv(root / 'X.data' / 'joined_data' / 'base_location_data.csv')\n",
    "print(gdf_df.shape)\n",
    "valid_mask = gdf_df['valid_accident_location_filter'] == True\n",
    "gdf_valid_df = gdf_df[valid_mask]\n",
    "gdf_valid_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_all = gdf_all[~(gdf_all.hex_id == '0')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collision_year_list = [2014, 2015, 2016, 2017, 2018, 2019, 2020]\n",
    "neg_sample_dict = {}\n",
    "for year in collision_year_list:\n",
    "    neg_sample_dict[year] = pd.read_csv(root / 'X.data' / 'neg_samples' / ('neg_samples_' + str(year) + '.csv'),low_memory = False)\n",
    "neg_sample_df = pd.concat(neg_sample_dict.values(), ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_sample_df.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_doy_to_date(row):\n",
    "    doy = str(row.doy)\n",
    "    year = str(row.year)\n",
    "    doy.rjust(3 + len(doy), '0')\n",
    "    new_date = datetime.strptime(year + \"-\" + doy, \"%Y-%j\").strftime(\"%m-%d-%Y\")\n",
    "    return new_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import choices\n",
    "def sample_date_time_creation(frame):\n",
    "    frame['collision_date'] = pd.to_datetime(frame['date'])\n",
    "    frame['collision_month']  = frame['collision_date'].dt.month\n",
    "    frame['collision_dayofweek']  = frame['collision_date'].dt.dayofweek\n",
    "    frame['collision_year']  = frame['year']\n",
    "    frame['accident_count'] = 0\n",
    "    # panda frame hours range from 0 to 23\n",
    "    frame['collision_hour'] = choices(range(24),k=frame.shape[0])\n",
    "    frame = frame[['hex_id', 'collision_year', 'collision_month', 'collision_dayofweek', 'collision_hour', 'accident_count']]\n",
    "    return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_sample_df['date'] = neg_sample_df.apply(convert_doy_to_date, axis=1)\n",
    "neg_sample_df = sample_date_time_creation(neg_sample_df)\n",
    "neg_sample_df['accident_count'] = 0\n",
    "neg_sample_df.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_sample_df = pd.read_csv(root / 'X.data' / 'h3_processed_data' / 'collisions_hex.csv', low_memory = False)\n",
    "pos_sample_df = pos_sample_df[['hex_id', 'collision_year', 'collision_month', 'collision_dayofweek', 'collision_hour', 'accident_count']]\n",
    "print(pos_sample_df.shape)\n",
    "pos_sample_df.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_sample_df = pos_sample_df[pos_sample_df['hex_id'].isin(gdf_valid_df['hex_id'])]\n",
    "pos_sample_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#concatenate and attach test/train/validate and out of time.\n",
    "neg_pos_sample_df = pd.concat([pos_sample_df, neg_sample_df])\n",
    "neg_pos_sample_df.sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_pos_sample_df[neg_pos_sample_df['accident_count'] == 0].collision_year.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_pos_sample_df[neg_pos_sample_df['accident_count'] == 1].collision_year.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_pos_sample_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate random floating point values\n",
    "from random import seed\n",
    "from random import random\n",
    "# seed random number generator\n",
    "seed(1)\n",
    "random_list = list()\n",
    "# generate random numbers between 0-1\n",
    "for _ in range(neg_pos_sample_df.shape[0]):\n",
    "\trandom_list.append(random())\n",
    "len(random_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_pos_sample_df['random'] = pd.Series(random_list)\n",
    "neg_pos_sample_df['ttv_split'] = np.where(neg_pos_sample_df['random']<=.5, 'Train',\n",
    "                                 np.where(neg_pos_sample_df['random']<=.8, 'Test','Validate'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_pos_sample_df.ttv_split.value_counts()/neg_pos_sample_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_pos_sample_df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_pos_sample_df.to_csv(root / 'X.data' / 'TTV_splits' / 'TTV_data.csv', index = False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
